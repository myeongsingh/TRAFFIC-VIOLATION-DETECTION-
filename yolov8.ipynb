{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6c0d167-94af-41ca-888f-ebc4199019ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.2.11)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.13.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.3.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\arjun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a073b54-0476-41a7-89ea-63e9b4ddbb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.2.11'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ccf4cde9-c8fe-4986-b023-0ffc01fc43ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'yolov8h.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtracker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 6\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myolov8h.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:151\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:240\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    237\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:806\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 806\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:732\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    726\u001b[0m         {\n\u001b[0;32m    727\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    730\u001b[0m         }\n\u001b[0;32m    731\u001b[0m     ):  \u001b[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yolov8h.pt'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import*\n",
    "\n",
    "model=YOLO('yolov8h.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a6b85f3-998a-4244-b4e4-b85ea035f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', \n",
    "              'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2fc11a5-a706-4108-9faa-2e6901b347e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker=Tracker()\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1455ba7-7b08-4a0a-b25a-c6e1c92401e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r\"C:\\Users\\arjun\\OneDrive\\Desktop\\speed detection\\highway.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e49f6ab5-1906-423c-ae88-a43c6599d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4699840f-579a-4c40-8d92-f287edd51556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 8 cars, 2 trucks, 254.9ms\n",
      "Speed: 0.0ms preprocess, 254.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 203.9ms\n",
      "Speed: 0.0ms preprocess, 203.9ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 2 trucks, 181.9ms\n",
      "Speed: 0.0ms preprocess, 181.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 2 trucks, 92.9ms\n",
      "Speed: 0.0ms preprocess, 92.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 79.4ms\n",
      "Speed: 0.0ms preprocess, 79.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 79.4ms\n",
      "Speed: 0.0ms preprocess, 79.4ms inference, 15.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 111.0ms\n",
      "Speed: 0.0ms preprocess, 111.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 95.5ms\n",
      "Speed: 6.5ms preprocess, 95.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 2 trucks, 79.0ms\n",
      "Speed: 15.6ms preprocess, 79.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 2 trucks, 110.2ms\n",
      "Speed: 0.0ms preprocess, 110.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 100.0ms\n",
      "Speed: 0.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 95.3ms\n",
      "Speed: 0.0ms preprocess, 95.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 79.8ms\n",
      "Speed: 0.0ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 79.2ms\n",
      "Speed: 0.0ms preprocess, 79.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 92.6ms\n",
      "Speed: 0.0ms preprocess, 92.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 79.3ms\n",
      "Speed: 0.0ms preprocess, 79.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 95.0ms\n",
      "Speed: 0.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 222.4ms\n",
      "Speed: 0.0ms preprocess, 222.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 1 truck, 449.3ms\n",
      "Speed: 0.0ms preprocess, 449.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 411.2ms\n",
      "Speed: 15.7ms preprocess, 411.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 472.2ms\n",
      "Speed: 0.0ms preprocess, 472.2ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 426.2ms\n",
      "Speed: 0.0ms preprocess, 426.2ms inference, 16.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 471.8ms\n",
      "Speed: 0.0ms preprocess, 471.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 156.1ms\n",
      "Speed: 0.0ms preprocess, 156.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 92.9ms\n",
      "Speed: 0.0ms preprocess, 92.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 126.2ms\n",
      "Speed: 15.6ms preprocess, 126.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 125.8ms\n",
      "Speed: 0.0ms preprocess, 125.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 94.4ms\n",
      "Speed: 0.0ms preprocess, 94.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 117.9ms\n",
      "Speed: 0.0ms preprocess, 117.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 111.0ms\n",
      "Speed: 0.0ms preprocess, 111.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 95.0ms\n",
      "Speed: 0.0ms preprocess, 95.0ms inference, 16.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 99.8ms\n",
      "Speed: 0.0ms preprocess, 99.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 133.2ms\n",
      "Speed: 0.0ms preprocess, 133.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 78.7ms\n",
      "Speed: 0.0ms preprocess, 78.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 94.6ms\n",
      "Speed: 0.0ms preprocess, 94.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 104.7ms\n",
      "Speed: 0.0ms preprocess, 104.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 110.7ms\n",
      "Speed: 0.0ms preprocess, 110.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 137.5ms\n",
      "Speed: 0.0ms preprocess, 137.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 174.6ms\n",
      "Speed: 0.0ms preprocess, 174.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "down = {}\n",
    "up = {}\n",
    "counter_down = []\n",
    "counter_up = []\n",
    "\n",
    "red_line_y = 198\n",
    "blue_line_y = 268\n",
    "offset = 6\n",
    "\n",
    "# Create a folder to save frames\n",
    "if not os.path.exists('detected_frames'):\n",
    "    os.makedirs('detected_frames')\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (1020, 500))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    # if count % 2 != 0:\n",
    "    #     continue\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data\n",
    "    a = a.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "    list = []\n",
    "\n",
    "    for index, row in px.iterrows():\n",
    "        x1 = int(row[0])\n",
    "        y1 = int(row[1])\n",
    "        x2 = int(row[2])\n",
    "        y2 = int(row[3])\n",
    "        d = int(row[5])\n",
    "        c = class_list[d]\n",
    "        if 'car' in c:\n",
    "            list.append([x1, y1, x2, y2])\n",
    "    bbox_id = tracker.update(list)\n",
    "\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, id = bbox\n",
    "        cx = int(x3 + x4) // 2\n",
    "        cy = int(y3 + y4) // 2\n",
    "\n",
    "        if red_line_y<(cy+offset) and red_line_y > (cy-offset):\n",
    "           down[id]=time.time()   # current time when vehichle touch the first line\n",
    "        if id in down:\n",
    "          \n",
    "           if blue_line_y<(cy+offset) and blue_line_y > (cy-offset):\n",
    "             elapsed_time=time.time() - down[id]  # current time when vehicle touch the second line. Also we a re minusing the previous time ( current time of line 1)\n",
    "             if counter_down.count(id)==0:\n",
    "                counter_down.append(id)\n",
    "                distance = 10 # meters \n",
    "                a_speed_ms = distance / elapsed_time\n",
    "                a_speed_kh = a_speed_ms * 3.6  # this will give kilometers per hour for each vehicle. This is the condition for going downside\n",
    "                cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "                cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)  # Draw bounding box\n",
    "                cv2.putText(frame,str(id),(x3,y3),cv2.FONT_HERSHEY_COMPLEX,0.6,(255,255,255),1)\n",
    "                cv2.putText(frame,str(int(a_speed_kh))+'Km/h',(x4,y4 ),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "\n",
    "                \n",
    "        #####going UP blue line#####     \n",
    "        if blue_line_y<(cy+offset) and blue_line_y > (cy-offset):\n",
    "           up[id]=time.time()\n",
    "        if id in up:\n",
    "\n",
    "           if red_line_y<(cy+offset) and red_line_y > (cy-offset):\n",
    "             elapsed1_time=time.time() - up[id]\n",
    "             # formula of speed= distance/time \n",
    "             if counter_up.count(id)==0:\n",
    "                counter_up.append(id)      \n",
    "                distance1 = 10 # meters  (Distance between the 2 lines is 10 meters )\n",
    "                a_speed_ms1 = distance1 / elapsed1_time\n",
    "                a_speed_kh1 = a_speed_ms1 * 3.6\n",
    "                cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "                cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)  # Draw bounding box\n",
    "                cv2.putText(frame,str(id),(x3,y3),cv2.FONT_HERSHEY_COMPLEX,0.6,(255,255,255),1)\n",
    "                cv2.putText(frame,str(int(a_speed_kh1))+'Km/h',(x4,y4),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    text_color = (0, 0, 0)  # Black color for text\n",
    "    yellow_color = (0, 255, 255)  # Yellow color for background\n",
    "    red_color = (0, 0, 255)  # Red color for lines\n",
    "    blue_color = (255, 0, 0)  # Blue color for lines\n",
    "\n",
    "    cv2.rectangle(frame, (0, 0), (250, 90), yellow_color, -1)\n",
    "\n",
    "    cv2.line(frame, (172, 198), (774, 198), red_color, 2)\n",
    "    cv2.putText(frame, ('Red Line'), (172, 198), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (8, 268), (927, 268), blue_color, 2)\n",
    "    cv2.putText(frame, ('Blue Line'), (8, 268), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.putText(frame, ('Going Down - ' + str(len(counter_down))), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame, ('Going Up - ' + str(len(counter_up))), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "    # Save frame\n",
    "    frame_filename = f'detected_frames/frame_{count}.jpg'\n",
    "    cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "    #if cv2.waitKey(0) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4882fdb-6063-4d71-b269-fc305bf55018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3328b90-a1b2-4f30-874e-f6e8cc079953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
